# 学习记录

## 软件架构^[https://developer.aliyun.com/article/930304] 
* laas
基础设施即服务
概念：需要帮助客户搭建好运行服务的基础设施，就是在线下筹备机房或机器，组成环境运行能够提供服务的项目并部署该项目提供服务。
举例：举例说就是我要在提供服务之前给客户那边搭建好线下的运行环境，比如在高校的校园中选择一个房间作为机房，在准备电脑进行组网，将项目运行在搭建好的机器上面就可以进行服务的访问。

* paas 
平台即服务
概念：利用云端搭建好操作系统或软件层面的如数据库、中间件等供用户使用，使得用户无需关注底层的基础设施和运行环境，只需要利用这些环境运行自己的应用和数据。
举例：就好比学校要使用我的就业管理系统进行管理，但是不想自己搭建机房和环境，所以就直接本地用少量的机器搭建客户端，将数据库、中间件或部分接口放在云端，请求时直接请求云端的接口和数据。

* saas
软件即服务
概念：即云端已经将操作系统到运行环境到软件的客户端都已经搭建好了，使用方不需要安装任何环境或软件，只需要访问客户端就能直接使用、
举例：类似于在我的毕业生管理系统上，我先自己利用云端搭建好平台，然后如果有学校想要使用的话直接分配给他们一些账号和密码，他们就可以直接访问我搭建好的系统进行操作了。

## 分布式架构、微服务架构(MSA)
* 分布式
将一个大型的系统拆分成多个独立的子系统，这些子系统分布在不同的服务器或节点上，通过网络进行通信和协作，以完成整个系统的功能。
* 微服务
 将一个大型的应用拆分成多个小型的、独立的服务，每个服务都可以独立部署、扩展和维护。

## 分布式事务
### 由来
1. 单体项目
一个模块对应一个数据库中的多张表
采用本地**@Transactional**即可解决
2. 分布式项目1
多个模块对应一个数据库中的多个表
采用消息中间件即可解决
3. 分布式项目2
多个模块对应多个数据库中的多个表
采用消息中间件和Seata都可，偷懒使用Seata，自己实现可以使用消息中间件
注：seata是开源的分布式事务解决方案，力于提供高性能和简单易用的分布式事务服务。为用户提供了AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。

### 属性
原子性、一致性、隔离性、持久性，即ACID
原子性：一个事务中的所有操作，要么全部成功，要么全部失败。
一致性：在事务开始前，进行时，结束后，数据库的完整性没有得到破坏。
隔离性：数据库允许多个并发事务同时对数据进行读写和修改的能力。
持久性：事务处理结束后，对数据的修改是永久性的，即使系统故障也不会丢失。

### 分布式事务^[https://segmentfault.com/a/1190000040321750#item-2-5]
* 概念
不同的服务之间通过网络协调完成的事务（由于数据库资源分布在不同的服务器上，可能由不同的事务管理器管理）。
* 场景^[https://developer.aliyun.com/article/1280619]
1. 电子商务平台
一个电子商务中，涉及到订单生成、库存扣减、支付扣款等多个操作，在分布式环境下需要保证事务一致性，避免订单与库存不一致现象。
2. 分布式数据库
3. 分布式消息队列
4. 分布式缓存
5. 分布式文件系统
* 解决方案
1. 两阶段提交(2PC)/XA、三阶段提交(3PC)
XA事务组成：
多个资源管理器(RM)+一个事务管理器(TM)+应用程序(AP)
第一阶段（prepare）： 所有的参与者(RM)准备执行事务并锁住需要的资源。参与者ready时，向TM报告已准备就绪。
第二阶段（commit/rollback）：当事务管理器(TM)确认所有的参与者(RM)都ready后，向所有参与者发送commit命令。如果任何一个参与者prepare后，TM会通过所有完成的prepare的参与者进行回滚。
特点：
（1）简单易理解
（2）锁住资源时间过程，并发度低。
2. Sage
将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。
3. TCC
Try - Confirm - Cancel
三阶段：
try阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）
confirm阶段：确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作要求具备幂等设计，Confirm 失败后需要进行重试。
cancel阶段：取消执行，释放 Try 阶段预留的业务资源。
Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致，要求满足幂等设计。
特点：
（1）并大量较高，无长期资源锁定
（2）开发量较大，需要提供try/confirm/cancel接口
（3） 一致性较好，不会发生SAGE已扣款最后转账失败的情况
（4）适用性订单类业务，对中间状态有约束的业务
4. 本地消息表
通过消息的方式来异步确保执行。
写本地消息和业务操作放在一个事务里，保证了业务和发消息的原子性，要么他们全都成功，要么全都失败。
流程：
创建本地消息表，并轮询消息。
特点：
（1）不支持回滚
（2）轮询生产消息难实现，如果定时轮询会延长事务总时长，如果订阅binlog则开发维护困难
场景：
可异步执行的业务，且后续操作无需回滚的业务
容错机制：
（1）上一个操作事务失败，事务直接回滚，无后续步骤
（2）轮序生产消息失败，下一个操作事务失败都会进行重试
5. 事务消息
实际就是把本地消息表的实现方式，通过使用MQ的方式来实现消费，减少了创建本地消息表和轮询的流程，如rocketmq
解决了生产端的消息发送与本地事务执行的原子性问题。
发送与提交：
（1）发送消息（half消息）
（2）服务端存储消息，并响应消息的写入结果
（3）根据发送消息执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）
（4）根据本地事务状态执行commit/rollback（Commit操作发布消息，消息对消费者可见）
补偿流程：
对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”Producer收到回查消息，返回消息对应的本地事务的状态，为Commit或者Rollback事务消息方案与本地消息表机制非常类似，区别主要在于原先相关的本地表操作替换成了一个反查接口
特点：
（1）长事务仅需要分拆多个任务，并提供一个反查接口，使用简单
（2）事务消息的回查没有好的方案，极端情况可能存在数据错误
场景：
可异步执行的业务，且后续操作无需回滚的业务
6. 最大努力通知
发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是可能消息接收不到，此时需要接收通知方主动调用发起通知方的接口查询业务处理结果，通知的可靠性关键在接收通知方。
解决方案：    
（1）提供接口，让接受通知方能够通过接口查询业务处理结果
（2）消息队列ACK机制，消息队列按照间隔1min、5min、10min、30min、1h、2h、5h、10h的方式，逐步拉大通知间隔 ，直到达到通知要求的时间窗口上限。之后不再通知
场景：
适用于业务通知类型，微信交易的结果，就是通过最大努力通知方式通知各个商户，既有回调通知，也有交易查询接口
7. AT事务模式

### 分布式幂等性^[https://blog.csdn.net/u014618114/article/details/114810016]
* 概念
 接口的幂等性实际上就是接口可重复调用，在调用方多次调用的情况下，接口最终得到的结果是一致的。实现幂等性，就是对一个接口多次发起同一个请求，这个接口得保证结果是准确的。
 * 解决方案
 1. 每个请求必须有一个唯一的标识,数据库表加唯一索引，防止新增脏数据。
 2. 分布式锁，利用redis，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路。
 3. token机制，防止重复提交, 业务要求页面的数据只能被点击提交一次, 但是可能由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交。
 利用 Token + Redis 验证来防止重复提交
* Client 没有 token，请求 Server，获取 token。
* Server 生成 token，并缓存到 Redis 中，返回 token 给 Client
* Client 带着 Token（放到报文头），请求 Server 进行业务操作
* Server 首先验证 Token，在 Redis 查询该 Token 是否存在
  * Redis 有 Token，说明是第一次提交，执行业务，redis(单线程)并删除 Token
  * Redis 没 Token，说明是重复提交，不执行业务，返回拒绝请求。

### 分布式锁^[https://www.cnblogs.com/liuqingzheng/p/11080501.html] ^[https://developer.aliyun.com/article/871736]
* 概念
是一种机制，用于在分布式系统中保证多个进程或线程在访问共享资源时不会发生冲突，从而保证数据的一致性和系统的稳定性。
* 场景
多线程对同一资源的竞争
* 作用
1. 保证数据一致性
2. 避免重复处理数据
* 实现方式
对于单机系统可以使用java自带的Synchronized、ReentrantLock。
1. 基于数据库的分布式锁
创建一个表，确定唯一索引，如mysql，利用数据库的唯一约束或行锁定机制实现。
2. 基于缓存的分布式锁
利用缓存系统(如redis)来实现原子操作
3. 基于ZooKeeper的分布式锁
利用ZooKeeper的临时顺序节点和监听机制来实现
4. 一些自研的分布式锁(Chubby)

### 分布式事务与分布式锁区别^[https://cloud.tencent.com/developer/article/2304244]
1.  目标
分布式事务的主要目标是保证多个操作的一致性，即要么所有操作都成功提交，要么全部失败回滚；
分布式锁的主要目标是保证在分布式环境下的资源互斥访问，即同一时间只有一个客户端能够获取到锁并执行相关操作。
2. 应用场景
分布式事务通常用于需要跨多个数据库或服务的复杂操作，如订单支付、库存扣减等。
分布式锁通常用于需要保证资源的独占性和顺序性的场景，如分布式任务调度、分布式缓存更新等。
3. 实现方式
分布式事务通常使用协议来实现，如2PC、3PC、TCC等。
分布式锁可以使用不同的实现方式，如基于数据库、缓存或分布式协调服务等。
4. 性能和可用性
分布式事务的实现通常会带来性能上的开销和可用性上的挑战，如网络延迟、单点故障等。
分布式锁的实现方式可以选择更适合的方案，以平衡性能和可用性需求。

## 中间件
### MongoDB^[https://www.runoob.com/mongodb/mongodb-tutorial.html]
* 概念
开源**文档型数据库**,类似JSON 的文档模型存储数据
基于文档的 NoSQL 数据库
旨在为 WEB 应用提供可扩展的高性能数据存储解决方案
介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。
* 场景
1. 网站实时数据
2. 数据缓存
3. 大尺寸低价值数据的存储
4. 高伸缩性场景
5. 对象或JSON数据存储

### Elasticsearch^[https://elasticsearch.bookhub.tech/intro/]
* 概念
1. 是分布式搜索和分析引擎
2. 分布式文档存储(相当于数据库)
* 场景
1. 全文检索
2. 应用查询
3. 大数据领域
4. 日志检索
5. 监控领域
6. 机器学习

### MongoDB与Elasticsearch作为存储的区别
相同：
都有文档存储的功能
不同：
Elasticsearch更多是基于**查询搜索**的分析型数据库，MongoDB 定位于事务型应用层面 OLTP(在线事务处理)^[https://developer.aliyun.com/article/770889]

### ZooKeeper^[https://zookeeper.net.cn/] ^[https://zookeeper.net.cn/doc/r3.9.2/zookeeperOver.html]
* 概念
开源的**分布式协调服务**。主要用于分布式应用程序。
* 场景^[https://developer.aliyun.com/article/1267570]
1. 数据同步
2. 配置管理
3. 命名服务
4. 分布式锁
5. 分布式队列

### Mysql
#### 存储引擎
1. MyISAM
不支持事务，行级锁和外键约束
2. MyISAM Merge
把相同的MyISAM合并成一张虚表，主要用于日志和数据仓库
3. InnoDB
4. Memory
把数据存放内存中，主用于临时表中
5. archive
 只支持select 和 insert语句，而且不支持索引。常应用于日志记录和聚合分析方面

### ShardingSphere^[https://shardingsphere.apache.org/document/legacy/4.x/document/cn/overview/]
* 概念
是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。    
均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。
#### Sharding-JDBC
* 分片
  * 垂直分片(纵向分片)
按照业务拆分的方式
理念：专库专用
按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。
  * 水平分片(横向拆分)
通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。
水平分片从理论上突破了单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案。
* 场景
1. 电商平台
2. 社交网络
3. 物联网

### 缓存
#### redis^[https://www.redis.net.cn/]
* 概念
内存存储的数据结构服务器，可用于数据库、高速缓存和消息队列代理。

#### Memcached
* 概念
是一个分布式内存对象缓存系统
* 场景^[https://blog.csdn.net/weixin_52938153/article/details/140254397]
1. 加速数据库查询
频繁的数据库查询可能导致严重的性能问题，尤其是当数据库需要处理大量的并发请求时。通过Memcached缓存数据库查询结果，可以显著减少数据库的负载，提高查询性能。
2. 缓存API调用结果
大数据应用中，经常需要调用外部API获取数据，如天气信息
3. 缓存页面片段
生成动态页面通常需要进行大量的数据处理和数据库查询
4. 分布式缓存
将数据分布在多个Memcached节点上，实现负载均衡和横向扩展。

#### redis与Memcached区别^[https://juejin.cn/post/7340512262166036491]
* 性能
读写上，redis6.0后引入多线程处理IO操作，性能得到提高；
并发上，Memcached使用非阻塞IO和多线程的架构设计，性能高，redis由于是单线程模型，存在处理大量连接是遇到瓶颈。
* 功能
类型上，Memcached只支持简单的键值对，适用于存储简单数据，而redis支持多种类型，如string、list列表、set集合、sorted set有序集合、hash哈希等
持久化上，redis支持持久化，Memcached只是一个缓存解决方案
分布式支持上，Redis提供了哨兵(Sentinel)系统和集群(Cluster)模式，能够在节点间进行数据自动分片和复制；Memcached也支持分布式，但需要客户端或代理来实现数据分片逻辑
数据一致性和原子性上，redis支持事务，能保证一系列操作的原子性；Memcached不支持事务，适用于对数据一致性要求低的场景
* 场景
redis，需要利用复杂数据结构、高级功能（如发布/订阅、持久化、事务）的场景；需要构建具有数据持久化需求的应用程序；适合作为构建微服务架构中的消息队列、分布式锁等组件。
Memcached，适用于简单的缓存场景，特别是当缓存对象较大、读写操作频繁，且不需要持久化，数据一致性和原子性要求不高的场景。

### Dubbo
* 概念
web和rpc框架

### shiro
* 概念
开源安全框架，可以干净地处理身份验证，授权，企业会话 Management 和加密。


## IO

## 多线程
### 线程^[https://cloud.tencent.com/developer/article/2339282]
#### 生命周期
1. 新建状态
2. 就绪状态
3. 运行状态
4. 阻塞状态
5. 等待状态
6. 超时等待状态
7. 终止状态
#### volatile关键字
修饰变量，其他线程可见修改值
#### 不返回执行结果线程
* 继承Thread
* 实现Runnale
#### 返回结果线程
* Callable
* Future
#### 线程池^[https://javaguide.cn/java/concurrent/java-thread-pool-summary.html#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90]
* 创建方式
1. 通过**ThreadPoolExecutor**构造函数来创建（推荐）。
2. 通过 Executor 框架的工具类 Executors 来创建（不推荐）。
  - 线程池类
    * FixedThreadPool
       固定线程数量的线程池
       该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
    * SingleThreadExecutor
       只有一个线程的线程池
       若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出(FIFO)的顺序执行队列中的任务。
    * CachedThreadPool
    可根据实际情况调整线程数量的线程池
    线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。
    * ScheduledThreadPool
    给定的延迟后运行任务或者定期执行任务的线程池
   - 弊端
   FixedThreadPool和SingleThreadExecutor使用容量大小为Integer.MAX_VALUE的无界队列（LinkedBlockingQueue），容易导致OOM
   CachedThreadPool使用容量大小为Integer.MAX_VALUE的同步队列（SynchronousQueue），容易导致OOM

### 锁机制^[https://blog.csdn.net/qq_34416331/article/details/107764522]
#### 锁分类
* 互斥锁
**只有一个线程能够访问被互斥锁保护的资源**
在访问共享对象之前，对其进行加锁操作。在访问完成之后进行解锁操作。加锁后，其他试图加锁的线程会被阻塞，知道当前线程解锁。解锁后，原本等待状态的线程变为就绪状态，重新竞争锁。
* 共享锁
允许多个线程共同访问资源
* 读写锁
既是互斥锁，又是共享锁。在**读模式下是共享锁，写模式下是互斥锁**。
#### 互斥锁
* Synchronized、Lock
1. synchronized 是 jvm 关键字，而 lock 是 java 类
2. synchronized 不用处理异常状态下的锁释放，**当资源使用完毕后或连接断开时自动释放锁**，而 Lock 需要**显示调用释放锁**
3. lock 接口提供了更多可适配的类和方法，包括非公平锁、读写锁等
4. 1.6版本后使用CSA算法，与lock性能差不多
* ReentrantLock 可重入锁
一种递归无阻塞的同步机制，也叫递归锁，指的是同一线程在外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码（在一个线程中可以多次获取同一把锁），但不受影响。ReentrantLock 和 synchronized 都是可重入锁。
* 公平锁、非公平锁、中断锁
  - 公平锁
公平锁即根据 FIFO 规则，从等待队列中取出第一个等待线程获取锁。
在并发环境下，每个线程在获取锁时会先查看此锁维护的等待队列，如果是空，或者当前线程是等待队列的第一个，就占有锁，否则会将自己加入到等待队列中。
  - 非公平锁
非公平锁下，新来的线程在一上来就会尝试直接占有锁，如果这时候刚好在发出请求时所变成可用状态，则这个锁会跳过队列中的等待线程，直接获得锁，否则，将自己加入到队列中。
可以通过 nonfairTruAcquire() 实现
  - 可中断锁
即等待锁的过程是可以中断的，在互斥锁中，synchronized 是不可中断所，而 Lock 是可中断锁。
ReentrantLock 中提供了 tryLock 和 lockInterruptibly 两种方法来中断等待操作
tryLock:
```java
public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireNanos(1, unit.toNanoc(timeout));
}
```
可以通过设置超时时间 timeout 以及单位 unit，在等待指定时间后，若还没有获取锁，则中断锁。
```java
if(lock.tryLock()){//尝试获取锁
    try {
        // ... 获取锁后要做的内容
    } catch (Exception e) {
        throw new Exception(e);
    } finally {
        lock.unlock();
    }
}else{
    // 指定时间内没有获取到锁
}
```
lockInterruptibly:
```java
public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}
```
    lockInterruptibly 调用后，就会马上主动中断等待，并抛出 InterruptedException  异常。
```java
public class TestLockInterruptibly {
    public static void main(String[] args) {
        Service s = new Service();
        Runnable  r = new Runnable() {
           @override
            public void run() {
                s.serviceMethod();
            }
        }
        Thread t = new Thread(r);
        t.start();
        Thread.sleep(50);
        Thread t2 = new Thread(r);
        t2.start();
        Thread.sleep(50);
        t2.interrupt();  // 线程2中断
    }
}

public class Service {
    private Lock lock = new ReentrantLock();   // 定义锁对象
    public void serviceMethod() {
        try{ 
              lock.lockInterruptibly();  // 如果线程被中断了，不会获得锁，会产生异常
              System.out.println(Thread.currentThread().getName() + "-- begin lock");
              for(int i = 0; i < Integer.MAX_VALUE; i++) {
                new StringBuilder();
              }
              System.out.println( Thread.currentThread().getName() + " -- end lock");
         }catch(InterruptedException e) {
             System.out.println(Thread.currentThread().getName + "*** exp");
         } finally {
            System.out.println( Thread.currentThread().getName() + " ***** 释放锁");
            lock.unLock();    
        }
   }
}
```

#### 共享锁
共享锁是指一个锁可以被多个线程持有，获得读锁的线程只能够读数据，不能够写数据
共享锁则是 ReentrantReadWriteLock 的读锁

#### 独享锁
独享锁即互斥锁，一个锁只能被一个线程锁持有，若锁被持有，其他线程不能在获得这个锁。获得锁的线程能够进行读写
常见的独享锁如 synchronized、Lock、ReentrantReadWriteLock的写锁

#### 读写锁 ^[https://cloud.tencent.com/developer/article/2334144]
ReadWriteLock
ReentrantReadWriteLock
* 概念
给一段临界区代码加锁，是对写进行互斥，对读进行共享的锁。
* 行为
读写之间的互斥：读的时候写阻塞，写的时候读阻塞，而且在读和写在竞争锁的时候，写会优先获取锁

#### 悲观锁、乐观锁
* 悲观锁
每一次去获取资源都认为会被修改，都需要加锁
场景：写多读少，在多写的情况下冲突经常发生，需要用锁来保证变量修改的有序性，如数据库中的行锁、表锁、读写锁等
实现方式：  synchronized 和 lock
* 乐观锁
每一次去获取资源否认为不会被修改，不加锁
但是更新数据的时候会去判断是否进行了修改操作，实现方式：数据库记录版本号等
场景：读多写少，即冲突很少发生的时候，省去了锁的开销，增大了吞吐量
实现方式：版本控制、CAS 算法


### 集合^[https://developer.aliyun.com/article/1400309]
#### 多线程环境下使用ArrayList
1. 使用同步机制(synchronized 或者 ReentrantLock)
2. Collections.synchronizedList(new ArrayList)
标准类库中synchronizedList的关键操作都带有synchronized
3. 使用 CopyOnWriteArrayList
CopyOnWrite容器即写时复制的容器，简称“COW”，也叫做“写时拷贝”。如果针对arraylist进行读操作，不做任何额外操作。如果是写操作，会拷贝一份新的arraylist,针对新的进行修改，修改过程中如果有读操作，就继续使用旧的数据，修改完成后，就会使用新的替代（本质上是一个引用之间的赋值，是原子的）
优点：不需要加锁，不会有锁竞争，读多写少的场景下性能高
缺点：arraylist不能太大，否则占用内存太大，而且新写的数据不能第一时间读到。
#### 多线程环境下使用队列
(1) ConcurrentLinkedQueue
非阻塞队列
使用 CAS 非阻塞算法来实现线程安全
适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 ConcurrentLinkedQueue 来替代。
(2) BlockingQueue
阻塞队列
广泛使用在“生产者-消费者”问题
原因是 BlockingQueue 提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。
是一个接口，继承自 Queue，常见实现类如下：
a. ArrayBlockingQueue 基于数组实现的阻塞队列
b. LinkedBlockingQueue 基于链表实现的阻塞队列
c. PriorityBlockingQueue 基于堆实现的带优先级的阻塞队列  
(3) TransferQueue 最多只包含一个元素的阻塞队列  
TransferQueue 的应用场景是，当不想生产者过度生产消息时，TransferQueue可能非常有用，在这样的设计中，消费者的消费能力将决定生产者产生消息的速度。
#### 多线程环境下使用哈希表
ConcurrentHashMap
* 好处
1. ConcurrentHashMap相比于HashTable 大大缩小了锁冲突的概率，把一把大锁,转换成多把小锁了
2. 针对读操作，不加锁，只针对写操作加锁
3. ConcurrentHashMap内部充分的使用了CAS，通过这个也来进一步的削减加锁操作的数目
4. 针对扩容,采取了"化整为零"的方式

## 高并发^[https://cloud.tencent.com/developer/article/1873371]
### 并发与并行
* 并行
  * 概念
    指系统同时执行多个任务，通过各个处理单元（cpu）分别来执行任务，以此来提高执行效率。
* 并发
  * 概念
  指系统同时管理多个任务的执行，这个可能不是同时执行任务，而是交替执行任务，但在一段时间内，只有一个任务处理执行状态。
### 高并发
* 概念
让单位时间同时处理任务的能力尽可能提高。
* 指标
1. 响应时间
2. 吞吐量
3. 并发用户数

## 网络通信
### TCP、UDP
* TCP
* UDP
* SOCKET

## Spring^[https://github.com/xuchengsheng/spring-reading]
### spring、springmvc、springboot、springcloud^[https://cloud.tencent.com/developer/article/1516989]
* spring
是java企业级应用开发框架，包含了IOC、AOP、事务等
* springmvc
是spring框架中的一个模块，主要用于构建web应用
* springboot
是spring框架对springmvc进行的一个封装，旨在快速构建web开发流程
* springcloud
是一个工具包，旨在管理与协调各个服务

### IOC、DI、AOP
* IOC、DI ^[https://cloud.tencent.com/developer/article/2373610]
IOC是一种设计模式，它是依赖注入（Dependency Injection，DI）的一种实现方式。在spring中，IOC是实现DI的技术，可以帮助开发人员管理和组织代码，提高代码的可重用型与可维护性。
  - 注入
  传统的实现方式是通过手动**new**的方式创建对象，现在通过IOC(控制反转)的方式，把对象交给容器进行管理。
  - 存储方式
  统一使用map结构来存储，spring
  - 优点
  降低代码耦合度
  - 原理
  使用**xml解析+反射+工厂模式**实现
* AOP
  - 概念
  面向切面编程，程序在不改变原有的程序逻辑的情况下，通过**预编译**和**运行期动态代理**增强方法。
  - 实现方式 ^[https://cloud.tencent.com/developer/article/1687821]
1. 使用 Spring API 实现  
```java
 <aop:config>
        <!--切入点 expression:表达式匹配要执行的方法-->
        <aop:pointcut id="pointcut" expression="execution(* com.cunyu.service.UserServiceImpl.*(..))"/>
        <!--执行环绕; advice-ref执行方法 . pointcut-ref切入点-->
        <aop:advisor advice-ref="userAfter" pointcut-ref="pointcut"/>
    </aop:config>
 ``` 
2. 自定义类来实现 AOP
```java
  <aop:config>
        <!--参照了自定义的切面类-->
        <aop:aspect ref="myPointCut"> 
            <aop:pointcut id="mypointcut1" expression="execution(* com.cunyu.service.UserServiceImpl.*(..))"/>
            <aop:after pointcut-ref="mypointcut1" method="after"/>
        </aop:aspect>
    </aop:config>
 ```
3. 使用注解实现
@Aspect
### spring三级缓存
* 三级缓存机制
一级缓存（Singleton Objects）：这是一个存储完全初始化好的bean的缓存。当一个bean被完全处理并准备好后，它会被放入这个缓存中。
二级缓存（Early Singleton Objects）：这个缓存存储的是早期暴露的对象，即还没有完全初始化的bean。这些对象已经被实例化，但可能还没有完成依赖注入和初始化。
三级缓存（Singleton Factories）：这个缓存存储的是bean工厂对象，它允许在bean完全初始化之前对其进行引用和操纵。
* 存储结构

| 缓存字段名    |  缓存级别   |   数据类型  |  描述   |
| --- | --- | --- | --- |
|  singletonObjects   |   1  |   Map<String, Object>  |  存储 Bean 的完成品，完全初始化   |
|  earlySingletonObjects   |  2   |   Map<String, Object>  |  存储 Bean 的半成品，尚未完成属性填充和初始化   |
|  singletonFactories   |  3   |  Map<String, ObjectFactory>   |  存储创建 Bean 的 ObjectFactory 对象，生成半成品 Bean 放入二级缓存   |

### SpringCloud事务
#### 声明式事务管理
使用@Transactional 注解
#### 分布式事务
* 使用场景
1. 多个模块操作同一个数据库中的多张表
2. 多个模块操作多个数据库中的多张表

## JVM

## 设计模式

## 算法
### CAS算法
* 概念
乐观锁技术，用于实现多线程并发控制
操作数：内存位置(V)、预期值(A)、更新值(B)
* 优点
无锁算法，可以在不使用锁的情况下实现并发控制。
是硬件对于并发操作共享数据的支持，一种无锁的非阻塞算法实现，乐观锁算法。
当且仅当V==A时，V==B，否则不做任何操作。
* 场景
1. 共享变量叠加的时候，比如volatile修饰解决不了原子问题
2. 批量插入进行排序时
3. lambda表达式里面 + 操作时（其实算是Lambda表达式下访问外部变量），否则编译报错

## 运维

## 操作系统

## 其他
### 支付设计

### 推送消息
1. 短链接
前端轮询
2. 长链接
3. iframe流
4. SSE
5. WebSocket
6. MQTT协议
7. 三方平台



## 参考文献
https://javaguide.cn/home.html